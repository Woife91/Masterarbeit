\chapter[Methoden]{Methoden}\label{sec:methoden}

\section{Implementierung Macenko}\label{sec:implementierung_macenko}
Die Implementierung des Algorithmus von Macenko erfolgte in Matlab. Für eine Schätzung der beteiligten Farbstoffe ist eine möglichst große Auswahl aus verschiedenen Zellklassen notwendig und Hintergrundtönen erforderlich. Hierfür wurde ein repräsentatives Set aus sieben Übersichtsbildern der Größe 2425x2056 ausgewählt, welches eine hohe Variabilität der genannten Eigenschaften aufweist. In Abbildung \ref{fig:mac_orig_bin} ist eines der Originalbilder zu sehen, außerdem sind im zugehörigen Binärbild jene Pixel weiß dargestellt, welche für die anschließende Auswertung verwendet werden. Dabei wurden Grenzwerte $\beta_{min} = 0.15$ und $\beta_{max} = 0.95$ im normierten OD-Raum als untere und obere Schranke festgelegt, um nicht gefärbte und chemisch gesättigte Pixel auszuschließen. 
\begin{figure}
\subfloat[Originalbild]{
\includegraphics[width=0.45\textwidth]
{pics/Methoden/mac_original}\label{fig:mac_orig}}
\quad
\subfloat[Relevante Pixel]{
\includegraphics[width=0.45\textwidth]
{pics/Methoden/mac_bin}\label{fig:mac_bin}}
\caption[Macenko: Identifizierung gefärbter Pixel]{Macenko: Die Grafik zeigt links das Originalbild, im Binärbild rechts sind die identifizierten relevanten Pixel in weiß dargestellt. \label{fig:mac_orig_bin}}
\end{figure}  
Für die relevanten Pixel wurde im Anschluss die Kovarianzmatrix anhand von Formel \ref{equ:covar} berechnet.
\begin{equation}
\label{equ:covar}
\mathbf{C} = \frac{1}{N-1}\sum_{i = 1}^N (\vec{x} - \vec{\mu})\cdot(\vec{x} - \vec{mu})^T
\end{equation}

Die Bestimmung der ersten beiden Hauptachsen erfolgte mittels Singärwertzerlegung (SVD) der Kovarianzmatrix. Dadurch wird diese in zwei orthogonale Matrizen $\mathbf{U}$ und $\mathbf{V}$ sowie die Matrix $\Sigma$, welche auf der Hauptachse die Singulärwerte der Matrix enthält und ansonsten Null ist, zerlegt. Die Singulärwerte sind außerdem entlang der Hauptachse der Größe nach geordnet, wobei der größte Wert an der Stelle $\mathbf{\Sigma_{0,0}}$ steht. Die beiden Hauptachsen, welche mit den beiden größten Eigenwerten korrespondieren sind aus diesem Grund die beiden ersten Spaltenvektoren in $\mathbf{U}$. 
\begin{equation}\label{equ:svd}
\text{SVD: }\mathbf{A} = \mathbf{U}\mathbf{\Sigma}\mathbf{V}^T
\end{equation}
In der Folge wurden die Pixelvektoren auf die Ebene projiziert, welche durch die beiden Hauptvektoren $\vec{u_1}$ und $\vec{u_2}$ aufgespannt wird. Als nächstem Schritt sollen die projizierten Vektoren normiert werden. Da die Ebene keine Ursprungsebene ist, liegt der normierte Vektor zunächst nicht wieder in der Ebene. Aus diesem Grund wird ein iteratives Verfahren angewendet, projizierte Vektor erst normiert wird, in dem durch seine Länge geteilt wird und dieser normierte Vektor dann wiederum auf die Ebene projiziert wird. Dieses Vorgehen wird solange fortgesetzt bis die Änderung kleiner einem $\epsilon$ ist. In Abbildung \ref{fig:norm_scheme} ist das Verfahren anhand des 2D-Falls vereinfacht dargestellt. Dort wird im Gegensatz zum realen Anwendungsfall ein Punkt auf eine Gerade projiziert und normiert. 
\begin{figure}
\center
\includegraphics[width = 0.95\textwidth]
{pics/Methoden/normalisation_scheme}
\caption[Iteratives Normalisierungsverfahren]{Iteratives Normalisierungsschema: Schwarz dargestellt ist die Gerade auf der Punkt zunächst liegt und am Ende auch wieder liegen soll. Der Einheitskreis, auf dem die normierten Punkte liegen müssen ist durch die grüne Linie angegeben. In blau dargestellt ist die Normierung in jedem Schritt, rot ist die orthogonale Projektion. Start- und Endpunkt des Verfahrens sind jeweils angegeben.\label{fig:norm_scheme}}
\end{figure}
In der vorliegenden Arbeit waren maximal zwei Iterationen notwendig. Der eingeschlossene Winkel zwischen Pixelvektoren und zweiter Hauptachse wird danach in ein Histogramm eingetragen. Das kumulierte Histogramm erlaubt im nächsten Schritt eine schnelle Ermittlung des stabilen Minimums und Maximums. Als Grenzwert wird $\alpha = 0.01$ verwendet, das heißt es wird jeweils das erste Feld von unten mit $p \geq \alpha$ bzw. von oben mit $p \leq 1-\alpha$ gesucht. Nachdem die jeweiligen Felder identifiziert sind, wird der jeweilige Mittelwert über alle Repräsentanten berechnet. Im Original von Macenko wird der Winkel zur ersten Hauptachse verwendet, im vorliegenden Fall, führt dies jedoch bei Winkeln $\gamma \approx \pi$ zu numerischen Fehlern. Durch die Änderung werden diese Winkel vermieden und das Resultat entspricht einer Verschiebung des Histogramms um $\frac{\pi}{2}$. Auf das Ergebnis hat die Veränderung keinen Einfluss. Abbildung \ref{fig:mac_proj} zeigt die einzelnen Schritte, von der originalen Punktwolke, über die projizierte Version zur normierten Version für alle relevanten Pixel aus dem Trainingsset. Außerdem ist das zugehörige Histogramm über alle Winkel abgebildet. Die y-Achse gibt hierbei die Wahrscheinlichkeit für die einzelnen Felder an. 
\begin{figure}
\subfloat[Originale Punktwolke]{
\includegraphics[width=0.45\textwidth]
{pics/Methoden/mac_notprojected}\label{fig:mac_cloud_orig}}
\quad
\subfloat[Projizierte Punktwolke]{
\includegraphics[width=0.45\textwidth]
{pics/Methoden/mac_projected}\label{fig:mac_cloud_proj}}
\quad
\subfloat[Normalisierte Punktwolke]{
\includegraphics[width= 0.45\textwidth]
{pics/Methoden/mac_normalised}\label{fig:mac_cloud_norm}}
\quad
\subfloat[Histogramm über die Winkel]{
\includegraphics[width = 0.45\textwidth]
{pics/Methoden/mac_histo_angles}\label{fig:mac_histo}}
\caption[Projektion und Winkelhistogramm]{Macenko: $\mathbf{(a)}$ Die originale Punktwolke, $\mathbf{(b)}$ Projizierte Punktwolke auf Ebene der Eigenvektoren. $\mathbf{c}$ Normalisierte Punktwolke. Rot ist jeweils der erste Hauptvektor dargestellt, blau der zweite. $\mathbf{(d)}$ Das Histogramm über die Winkel mit dem zweiten Hauptvektor. \label{fig:mac_proj}}
\end{figure}  
Für die relevanten Pixel wurde im Anschluss die Kovarianzmatrix anhand von Formel \ref{equ:covar} berechnet.
\begin{equation}
\label{equ:covar}
\mathbf{C} = \frac{1}{N-1}\sum_{i = 1}^N (\vec{x} - \vec{\mu})\cdot(\vec{x} - \vec{mu})^T
\end{equation}

\section{Implementierung Khan}
\label{sec:implementierung_khan}


\section{Eigener Workflow}\label{sec:eigener_workflow}

Im den folgenden Abschnitten soll aufgezeigt werden, inwiefern das Vorgehen von \citeauthor{khan2014nonlinear} und \citeauthor{macenko2009method} abgeändert wurde um die aufgetretenen Probleme zu umgehen.

\subsection[Color Deconvolution]{Color Deconvolution}\label{sec:own_cd}
In nächster Näherung wurden zunächst Stainvektoren für die Färbung nach Giemsa (Methylenblau und Eosin) verwendet, welche von \citeeig{landini2016} nach dem in Abschnitt \ref{sec:color_deconvolution} vorgestellten experimentellen Verfahren ermittelt wurden. Außerdem wurden als Vergleich die Stainvektoren benutzt, die mit Hilfe des von \citeauthor{macenko2009method} eingeführten Verfahrens bestimmt worden sind(\ref{sec:implementierung_macenko}). Für den jeweils fehlenden dritten Vektor, wird u.a. in der Arbeit von Khan angemerkt, dass dieser optimalerweise orthogonal zu den anderen beiden sein soll. Außer im Fall von Einheitsvektoren, würde dieser jedoch negative Komponenten enthalten, was im Modell die Folge hätte, dass die Absorption teilweise negativ wäre. Da dies mit der Realität nicht vereinbar ist, wurden als Lösung wurden zwei verschiedene Ansätze getestet. Die ersten beiden Zeilen der Stainmatrix sind bekannt und \citeauthor{landini2016} berechnet die dritte Zeile der Stainmatrix, in dem er zunächst die Spalten normalisiert, für den Fall dass die ersten beiden Komponenten nicht schon über $1.0$ liegen. Tritt dies doch ein, so wird das Element der dritten Zeile auf $0.0$ gesetzt. Im nächsten Schritt wird die Zeile normalisiert und Elemente die gleich $0$ werden zur Fehlerreduktion auf einen Wert $\epsilon = 0.01$ gesetzt. Diese Methode wurde der eigenen Idee gegenübergestellt, bei der zunächst über das Kreuzprodukt ein echt orthogonaler Vektor bestimmt wird. Dabei werden beide  Szenarien abhängig vom Vorzeichen berücksichtigt. Negative Komponenten werden auf $0.0$ gesetzt. Derjenige Vektor der nach dieser Operation die größere Länge aufweist, wird gewählt und normalisiert und als dritter Stainvektor eingesetzt. Unabhängig von der Wahl des dritten Vektors ist die Approximation für die vorhandenen Daten legitim, da der dritte Kanal für beide Fälle in gefärbten Bereichen keine Information aufweist. In Abbildung BLA sind Beispiele für die jeweiligen Zerlegungen gezeigt. 
\begin{figure}
\subfloat[Originalbild]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/original}\label{fig:cd1_original}}
\quad
\subfloat[Kanal 1, Giemsa]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor1}\label{fig:cd1_ch1}}
\quad
\subfloat[Kanal 2, Giemsa]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor2}\label{fig:cd1_ch2}}
\quad
\subfloat[Kanal 3, Giemsa, normalisierte Spalten]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor3}\label{fig:cd1_ch31}}
\quad
\subfloat[Kanal 3, Giemsa, ]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor3_orthGiemsa}\label{fig:cd1_ch32}}
\quad
\subfloat[Originalbild]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/original}\label{fig:cd2_original}}
\quad
\subfloat[Kanal 1, Macenko]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor1_macenko}\label{fig:cd2_ch1}}
\quad
\subfloat[Kanal 2, Macenko]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor2_macenko}\label{fig:cd2_ch2}}
\quad
\subfloat[Kanal 3, Macenko, normalisierte Spalten]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor3_macenko}\label{fig:cd2_ch31}}
\quad
\subfloat[Kanal 3, Macenko, orthogonale Stains]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor3_orthMacenko}\label{fig:cd2_ch32}}
\quad
\subfloat[Originalbild]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/original2}\label{fig:cd3_original}}
\quad
\subfloat[Kanal 1, Macenko]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor1_macenko2}\label{fig:cd3_ch1}}
\quad
\subfloat[Kanal 2, Macenko]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor2_macenko2}\label{fig:cd3_ch2}}
\quad
\subfloat[Kanal 3, Macenko, normalisierte Spalten]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor3_macenko2}\label{fig:cd3_ch31}}
\quad
\subfloat[Kanal 3, Macenko, orthogonale Stains]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor3_orthMacenko2}\label{fig:cd3_ch32}}
\caption[Color Deconvolution]{Verschiedene Ansätze für die Color Deconvolution. Die erste Reihe verwendet die experimentell gefundenen Stains, in der zweiten und dritten wurden sie nach Macenko (\ref{sec:implementierung_macenko}) bestimmt. Die erste Spalte zeigt das Originalbild, es folgen jeweils die Kanäle des ersten und zweiten Farbvektors. Spalte vier und fünf zeigen den dritten Vektor, der auf zwei verschiedene Arten bestimmt wurde. \label{fig:cd_examples}}
\end{figure} 
Eine Idee, die Zerlegung bildspezifisch zu optimieren, ist die Definition einer Zielfunktion für ein Optimierungsproblem, wobei als Initialstelle die Giemsa-Farbstoffe dienen können. Die Funktion ist von vier Parametern abhängig, nämlich den jeweils ersten beiden Elementen der Farbe repräsentierenden Stainvektoren. Dies ist nur möglich, falls nur zwei Grundfarbstoffe verwendet werden, da ansonsten der dritte Vektor nicht in Abhängigkeit der ersten beiden berechnet werden kann. Folgende Eigenschaften der Zerlegung wurden als mögliche Komponenten der Zielfunktion identifiziert:
\begin{itemize}
\item{Entropie in Kanal 3: Der dritte Kanal soll vor allem den Hintergrund repräsentieren, welcher keine relevanten Informationen beinhaltet. Die Entropie dient als Maß für den Informationsgehalt einer Quelle}
\item{Energie Kanal 3: Ähnlich wie im ersten Punkt geht es hierbei darum, der nicht farbrelevanten Komponente eine möglichst untergeordnete Rolle zuzuordnen}
\item{Abstand zur Hauptebene: Angelehnt an Macenko, wurde ein Maß eingeführt, dass den Abstand für gefärbte Pixel zur Hauptebene, welche durch die ersten beiden Stainvektoren definiert wird, verringert. Einfluss darauf, wie die beiden Vektoren innerhalb dieser Ebene liegen, hat dieses Maß keinen.}

\end{itemize}
\subsection{Bildclustering}\label{sec:clustering}

Um die Farbnormalisierung nach Khan durchzuführen, ist eine Zuordnung der Pixel in die Klassen "Gefärbt", "Hintergrund" und "Sonstiges" notwendig. Bei Khan wird diese durch einen Klassifikator realisiert, der für die vorliegenden Daten jedoch nicht geeignet war und schlechte Resultate lieferte. Aus diesem Grund wurde eine eigene Methode zur Identifikation der Cluster entwickelt. Zunächst werden mit Hilfe des Arcustangens aus Blau- und Grünkanal und einer Schwellwertbestimmung nach Otsu gefärbte Pixel identifiziert. Für den Hintergrund wird das Grauwertbild betrachtet. Die Histogramme weisen ein ausgeprägtes Maximum im Bereich hoher Intensitäten ($ > 200$) auf, wodurch der Hintergrund gut definiert ist. Der Schwellwert wird als erstes lokales Minimum unterhalb des Maximums festgelegt, wobei sowohl für die Bestimmung des Maximums als auch des Minimums ein gefiltertes Histogramm verwendet wird. Außerdem wird eine Minimaldistanz zwischen Maximum und Minimum eingeführt. Dadurch wird im Fall von zwei eng zusammenliegenden Maximumsspitzen vermieden, dass Teile des gesuchten Bereichs nicht erfasst werden. Der Bereich "Sonstiges", in den vor allem Erythrozyten fallen, grenzt sich deutlich vom Hintergrund ab, weswegen die Annahme, dass die Intensitätsdifferenz zwischen dem Maximum des Hintergrunds und Pixeln die in "Sonstiges" fallen mindestens fünf betragen sollte, valide ist. Der Fall eines sehr homogenen Hintergrund mit schmaler Spitze im Histogramm spielt eine untergeordnete Rolle, da die Intensitäten in "Sonstiges" stark streuen und ein Fehler des Schwellwerts $<5$ vernachlässigbar ist. Es gibt Fälle in denen kein Hintergrund zu sehen ist, bzw. dieser aufgrund leichter Färbung nicht mehr klar abgrenzbar ist. In diesen Fällen ist das Maximum dunkler als normal. Empirisch wurde der Bereich $ > 200$ festgelegt, für das ein gültiger Hintergrund gefunden werden kann. Für den Fall, dass das Maximum darunter liegt, wird für dieses Bild kein Hintergrund festgelegt. Dies hat Auswirkungen auf die Berechnung des Bsplines, da keine Merkmale für das Cluster vorhanden sind. Der Umgang mit diesem Fall wird in Abschnitt \ref{sec:bspline} beschrieben. 
\begin{figure}
\subfloat[Originalbild]{
\includegraphics[width=0.3\textwidth]
{pics/Methoden/original_target}\label{fig:seg_original}}
\quad
\subfloat[Arcustangens Blau und Grün]{
\includegraphics[width=0.3\textwidth]
{pics/Methoden/arctan}\label{fig:seg_arctan}}
\quad
\subfloat[Binärbild gefärbte Bereiche]{
\includegraphics[width=0.3\textwidth]
{pics/Methoden/bin_stained}\label{fig:seg_bin_stained}}
\quad
\subfloat[Grauwertbild]{
\includegraphics[width=0.3\textwidth]
{pics/Methoden/gray}\label{fig:seg_gray}}
\quad
\subfloat[Histogramm Grauwertbild]{
\includegraphics[width=0.3\textwidth]
{pics/Methoden/histogram}\label{fig:seg_histogram}}
\quad
\subfloat[Segmentierung]{
\includegraphics[width=0.3\textwidth]
{pics/Methoden/segmented}\label{fig:seg_seg}}
\caption[Eigene Segmentierung]{Die Abbildung zeigt relevante Zwischenergebnisse für den Segmentierungsansatz. $(\mathbf{(c)}$ Weißer Bereich signalisiert gefärbten Bereich im Original. $\mathbf{(e)}$ Rote Linie markiert den gesuchten Schwellwert. Höhere Intensitäten werden dem Hintergrund zugeordnet. $\mathbf{(f)}$ Weiß: Gefärbt, helles Grau: Sonstiges, dunkles Grau: Hintergrund, Schwarz: Keine Zuordnung\label{fig:bsplines_example}}
\end{figure} 
Nach der Bestimmung der Bereiche "Hintergrund" und "Gefärbt" ergibt sich "Sonstiges" aus den bisher nicht festgelegten Pixeln. Vorausgesetzt wird jedoch, dass diese Pixel nach der Color Deconvolution im dritten Kanal nicht weiß sind, da dies Eigenschaften des gefärbten Bereichs bzw. eines sehr hellen Hintergrunds wären. Die Farbeeigenschaft von hellerem Plasma wird durch den Arcustangens oft nicht komplett erfasst. Um zu vermeiden dass diese Bereiche anschließend "Sonstiges" zugeordnet werden, wird die oben genannte Bedingung gestellt. In Abbildung BLA sind einige Beispiele für die Segmentierung gezeigt. Es soll hierbei verdeutlicht werden, dass das Problem sehr vielschichtig ist.
 
\subsection{Anpassung}\label{sec:anpassung}

Wie in Kapitel \ref{sec:stand_der_technik} beschrieben, gibt es nach der Color Deconvolution verschiedene Möglichkeiten für die eigentliche Anpassung der Histogramme. Im Folgenden werden die Details der verschiedenen getesteten Ansätze beschrieben. 

\subsubsection{Bspline}\label{sec:bspline}
Die Implementierung der Bspline-Berechnung weißt viele Parallelen, aber auch Abweichungen gegenüber der von Khan (\ref{sec:bspline}) auf. Als Kontrollpunkte dienen die gleichen Merkmale der Histogramme, aber die Interpolation an den Sättigungsstellen ist unterschiedlich gesichert. Bei Khan gibt es mehrere zusätzliche Kontrollpunkte, in der vorliegenden Arbeit gibt es genau zwei. Dabei liegt einer am unteren, der andere am oberen Ende. Dass diese Punkte trotzdem interpoliert werden, liegt an der Anpassung des Knotenvektors, bei dem den entsprechenden Knoten eine Vielfachheit $n$ zugewiesen wird. Gleichzeitig entspricht $n$ auch dem Grad des Bsplines. Die verbleibenden Knoten werden gleichmäßig über das Parameterintervall verteilt. Eine optimale Schätzung wie bei \citeauthor{khan2014nonlinear}\ref{sec:khan} wird dabei nicht durchgeführt, allerdings ist der Grad des Bsplines und damit auch die Länge des Knotenvektors variabel.  

\subsubsection{Mittelwert und Standardabweichung}\label{sec:mean_std}
Wie in Kapitel \ref{sec:reinhard} beschrieben, können Histogramme durch eine Übertragung der statistischen Eigenschaften Mittelwert und Standardabweichung angepasst werden. Reinhard normierte dabei im $l\alpha\beta$-Farbraum, mit der Argumentation, dass hier stark dekorrelierte Kanäle vorliegen. Eine weitere Möglichkeit besteht darin, als Farbraumtransformation eine Color Deconvolution zu verwenden und in diesen getrennten Kanälen, die Anpassung durchzuführen. Die Beschreibung der relevanten Bildinformationen gelingt durch die Berücksichtigung der zugrundeliegenden chemischen Prozesse besser, was beim Prozess der Farbnormalisierung Vorteile bieten sollte. 

\subsubsection{Skalierung}\label{sec:skalierung}
Eine Skalierung der Histogramme fordert implizit, dass das Maximum der einzelnen Farbstoffe über verschiedene Zellbilder gleich ist. Diese Annahme kann so zwar nicht getroffen werden, jedoch kann bei geschickter Wahl des Zielmaximums der Kontrast so beeinflusst werden, dass sich Vorteile für die spätere Segmentierung ergeben. Eine Skalierung erfolgte in der Implementierung für diese Arbeit nur für ersten beiden Kanäle, also denjenigen, die auch Farbinformationen tragen. Das Maximum im dritten Kanal ist stark abhängig vom Erscheinungsbild der Erythrozyten aber auch von Verunreinigungen. Eine Normierung des dritten Kanals auf ein Pseudomaximum ist aus diesem Grund nicht zielführend, wenn es um eine Angleichung des Hintergrunds geht. 

\subsection{Auswahl Target}\label{sec:auswahl_target}

Erste Versuche zeigten, dass ein einzelnes Referenzbild nicht ausreicht, die Vielfältigkeit der Daten abzubilden. Aus diesem Grund wurde manuell ein Set aus 15 Bildern zusammengestellt, welches zum einen möglichst viele verschiedene Ausprägungen, sowie für die Segmentierung geeignete Bilder enthält. Nach Sichtung der Ergebnisse für die Anpassung an die Einzelbilder, konnte die Anzahl der Referenzbilder noch weiter reduziert werden, in dem diejenigen Bilder ausgewählt wurden, die hier die besten Ergebnisse lieferten. Für die Wahl der Referenz wurden unterschiedliche Konzepte entwickelt. Eine Möglichkeit besteht darin, eine Art mittleres Referenzbild zu berechnen, indem für jedes Merkmal, der Mittelwert aller korrespondierenden Merkmale der Referenzbilder gewählt wird. Eine Abwandlung hierzu ist es, den Median anstelle des Mittelwerts zu verwenden, wodurch Ausreißer kein Gewicht bekommen. In beiden Fällen bleiben die Referenzmerkmale für alle zu normalisierenden Bilder gleich. Eine andere Möglichkeit ist es für jedes Bild eine hinsichtlich der Merkmale möglichst ähnliche Referenz auszuwählen. Dadurch ist die Gefahr einer Verfälschung der Bildinformationen am wenigsten gegeben, der Grad der Anpassung über ein ganzes Set hinweg ist jedoch auch geringer. 

\section[Segmentierung]{Segmentierung}\label{sec:segmentierung}

\subsection{Algorithmus}\label{sec:seg_algo}
Eine Automatisierung der Differenzialzählung erfordert zunächst eine stabile Segmentierung der einzelnen Zellen. \citeeig{krappe2015dynamic} stellen hierzu ein Verfahren vor, bei dem im ersten Schritt die Zellzentren detektiert werden sollen. Es wird ein Grauwertbild mit Hilfe eines gewichteten Quotienten von Grün- und Blaukanal generiert. Otsu-Thresholding führt im Anschluss zu einem Binärbild, in dem durch Zählen der schwarzen und weißen Pixel entschieden wird, ob das Bild viele oder wenige gefärbte Flächen enthält, wovon das weitere Vorgehen abhängt. Ist viel Vordergrund enthalten, so werden mit Hilfe morphologischer Operatoren Löcher im innerhalb weißer Flächen aufgefüllt. Für die Ermittlung potentieller Zellzentren, wird eine Wasserscheidentransformation auf dem gaußgefilterten oben beschriebenen Grauwertbild durchgeführt. Regionen welche eine Größe von 2500 Pixeln überschreiten, werden in eine Graphendarstellung umgewandelt. Falls gefundene Zentren eine euklidische Distanz von weniger als 70 Pixeln aufweisen, so wird davon ausgegangen, dass diese Knoten auf die gleiche Zelle verweisen, weshalb sie durch einen neuen Knoten ersetzt werden, der den Mittelwert repräsentiert. Dieser Schritt ist Abbildung \ref{fig:cell_centers} dargestellt.
\begin{figure}
\subfloat[Vor Korrektur: eine Zelle wird durch zwei Zentren beschrieben]{
\includegraphics[width=0.45\textwidth]
{pics/Grundlagen/centers_uncorrected}\label{fig:seg_uncorrected}}
\quad
\subfloat[Nach Korrektur: Jede Zelle mit nur einem Zentrum]{
\includegraphics[width=0.45\textwidth]
{pics/Grundlagen/centers_corrected}\label{fig:seg_corrected}}
\quad
\caption[Identifizierung Zellzentren]{Im Korrekturschritt werden Zentren mit geringer Distanz, grün markiert in $\mathbf{(a)}$, zu einem Zentrum zusammengefügt $mathbf{(b)}$. \label{fig:cell_centers}}
\end{figure} 
Hat das Bild dagegen einen hohen Vordergrundanteil, so wird eine Hintergrundkorrektur durchgeführt, bei der dieser durch ein 2D-Polynom dritten Grades approximiert wird. Der Vordergrund wird zunächst mit Hilfe eines Mittelwertfilters geschätzt und dann unter Verwendung des "Fast Marching"-Algorithmus konkretisiert. In der Folge werden homogene Regionen mit dem "Color Structure Code" extrahiert und als geordneter Graph dargestellt. Die Blätter dieses Graphen sind die potentiellen Zellzentren, die anhand des gleichen Verfahrens wie im Fall mit viel Vordergrund korrigiert werden. 
Um in der eigentlichen Segmentierung den äußeren Rand und die Grenze zwischen Zellkern und Zellplasma zu bestimmen, wird für jede Zelle eine Polartransformation mit dem im vorherigen Schritt gefundenen Zentrum durchgeführt. Es wird eine zu minimierende Kostenfunktion eingeführt, die aus sechs Komponenten besteht:
\begin{itemize}
\item{Gradient des gaussgefilterten Farbbild}
\item{Radius mit spezifischem minimalen und maximalem Radius \color{red} Komisches Bild, Wiederholung, Sebastian fragen,  BLABLA \color{black}}
\item{Gewichtung anhand Arcustangens von Blau- und Grünkanal}
\item{Unterschied zum vorher bestimmten Durchschnitt der Hintergrundpixel  \color{red} "Distance transform" = geht in Richtung invers?, Sebastian fragen,  BLABLA \color{black}}
\item{Unterschied zum vorher bestimmten Durchschnitt der Vordergrundpixel}
\item{SLIC Superpixel + Distanzmaß als Gewichtung}
\end{itemize}

Der Weg im Kostenbild von 0-6$\pi$ soll minimiert werden. Durch die dreifache Wiederholung wird verhindert, dass Anfang und Endpunkt des Weges nicht übereinstimmen. Dies hätte zur Folge, dass die Segmentierung im späteren Bild nicht geschlossen ist und einen Sprung aufweist. Die inverse Polartransformation überführt die segmentierende Linie zurück in den ursprünglichen Bildraum. Abbildung \ref{fig:seg_outer_borders} soll die einzelnen Schritte anhand eines Beispiels verdeutlichen.
\begin{figure}
\center
\subfloat[Originalbild]{
\includegraphics[width=0.35\textwidth]
{pics/Grundlagen/seg_orig}\label{fig:seg_original}}
\quad
\subfloat[Polartransformiertes Original, dreifach aneinandergehängt]{
\includegraphics[width = 0.9\textwidth]{pics/Grundlagen/seg_polar}\label{fig:seg_polartransform}}
\quad
\subfloat[Kostenfunktion]{
\includegraphics[width = 0.9\textwidth]{pics/Grundlagen/seg_function}\label{fig:seg_costfunction}}
\quad
\subfloat[Weg mit minimalen Kosten]{
\includegraphics[width = 0.9\textwidth]{pics/Grundlagen/seg_min}\label{fig:seg_min}}
\quad
\subfloat[Hervorgehobenes Ergebnis Segmentierung]{
\includegraphics[width=0.35\textwidth]
{pics/Grundlagen/seg_seg}\label{fig:seg_seg}}
\quad
\caption[Segmentierung mittels Polartransformation]{$\mathbf{(a)}$ Originalbild; $\mathbf{(b)}$ Polartransformation mit Zentrum der Zelle als Nullpunkt; $\mathbf{(c)}$ Kostenfunktion, wobei die Kosten in den dunklen Bereichen minimal sind; $\mathbf{(d)}$ Auswertung der Kostenfunktion: Grüne Linie entspricht Weg mit den geringsten Kosten; $\mathbf{(e)}$ Inverse Polartransformation, heller Bereich entspricht der segmentierten Zelle \label{fig:seg_outer_borders}}
\end{figure}
Die Unterscheidung zwischen Plasma und Zellkern wird wieder auf dem Graubild realisiert, welches durch den Arcustangens von Blau und Grün gebildet wird. Dafür wird das Histogramm der Pixel, die innerhalb der zuvor segmentierten Zelle liegen, bestimmt. Mit Hilfe der Grenzwertbestimmung von Otsu wird das Histogramm und dadurch auch das Bild in zwei verschiedene Bereiche aufgeteilt.

\subsection{Evaluierung}\label{sec:seg_eval}
%TODO
\color{red}
PAPER!
\color{black}
Für die Evaluation der Segmentierung, wurde der automatische Algorithmus mit den als Grundwahrheit dienenden manuell bestimmten Daten verglichen. Das verwendete Maß ist dabei eine Kombination aus Unter- bzw. Übersegmentierung und dem AOM-Kriterium, welches den Überlappungsbereich beschreibt. 

\noindent AOM-Kriterium:
\begin{equation}
Q_1 = \frac{|T\cap A|}{|T\cup A|}
\end{equation}
Übersegmentierung:
\begin{equation}
Q_2 = \frac{|T\setminus (A\cap T)|}{|T|}
\end{equation}
Untersegmentierung:
\begin{equation}
Q_3 = \frac{|A\setminus (A\cap T)|}{|A|}
\end{equation}

Soll Segmentierung der Zelle als ganzem betrachtet werden, so ist $A$ die Menge aller Punkte, welche laut automatischer Segmentierung zur Zelle gehören. $T$ steht für die äquivalente Menge entsprechend der Grundwahrheit. Für eine Auswertung, welche zudem die Aufteilung zwischen Zellkern- und Plasma berücksichtigt, dient der Nucleus als Region of Interest.
  
\section[Klassifizierung]{Klassifizierung}\label{sec:klassifizierung}
\subsection{Algorithmus}\label{sec:klass_algo}
%TODO
\color{red}
 Paper fehlt noch in Quellen!! Veröffentlichung abwarten?
\color{black}
Der zweite wichtige Baustein für eine automatisierte Differentialzählung ist die Zellklassifikation, welche der Segmentierung nachfolgt. In diesem Schritt soll die Zelle einer von 16 Klassen zugeordnet werden. Hierbei soll das Wissen über die Hematopoese genutzt werden und in Form eines hierarchischen Baummodell nachgebildet werden, wie in Abbildung \ref{fig:classification_tree} dargestellt.
\begin{figure}
\center
\includegraphics[width = 0.95\textwidth]{pics/Grundlagen/classificationtree}
\caption[Hierarchisches Baummodell für die Klassifikation]{Darstellung des hierarchischen Baummodell, das die Hematopoese annähert\label{fig:classification_tree}}
\end{figure} 
Die für die Klassifikation verwendeten Merkmale teilen sich in Form, Textur und Farbe auf. Bei der Form spielen die gesamte Fläche, das Verhältnis aus Kern und Plasma, Konturmerkmale, Zernike Momente, normalisierte zentrale Momente, normalisierte Merkmale des Radius, Formfaktoren und Anzahl der Kernsegmente eine Rolle. Die Textur wird durch Local Binary Patterns, Grauwertmatrizen, Merkmale basierend auf Summen- und Differenzhistogrammen, farbbasierte Texturmerkmale, Charakterisierung von Heterogenität und Granularität, statistische Merkmale basierend auf Geometrie und Lauflängen, Texturmerkmale, die visuelle Eigenschaften von Oberflächen charakterisieren, und die fraktale Dimension beschrieben. Zur Beschreibung der Farbinformationen kommen im RGB-Raum statistische Merkmale der Histogramme sowie zentrale Momente zum Einsatz. Im HSV-Farbraum werden neben den zentralen auch noch andere Momente verwendet. Die extrahierten Merkmale werden mittels z-Transformation normalisiert.

In jedem Knoten des Baummodells wird ein "Einer-gegen-Alle"-Ansatz verwendet. Außerdem werden während des Lernprozess für jeden Knoten 100 Merkmale so ausgewählt, dass der Informationsgehalt möglichst groß wird, bei gleichzeitig geringer Redundanz. Von diesen 100 Merkmalen, werden im Anschluss mittels Merkmalsselektion die besten ausgewählt um eine Support Vector Machine (SVM) zu trainieren.  

\subsection{Evaluierung}\label{sec:klass_eval}
%TODO
Für die Evaluierung der Klassifikation spielt die Natur des Problems eine wichtige Rolle. Es ist aus medizinischer Sicht normal und tolerabel, dass die Unterscheidung zwischen Zellen unterschiedlichen Reifegrads oft nicht klar und deutlich erkennbar ist.