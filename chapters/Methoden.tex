\chapter[Methoden]{Methoden}\label{sec:methoden}

\section{Verfahren nach Macenko}\label{sec:implementierung_macenko}
Für eine Schätzung der beteiligten Farbstoffe ist eine möglichst große Auswahl aus verschiedenen Zellklassen notwendig und Hintergrundtönen erforderlich. Hierfür wurde ein repräsentatives Set aus sieben Übersichtsbildern der Größe 2425x2056 ausgewählt, welches eine hohe Variabilität der genannten Eigenschaften aufweist. In Abbildung \ref{fig:mac_orig_bin} ist eines der Originalbilder zu sehen, außerdem sind im zugehörigen Binärbild jene Pixel weiß dargestellt, welche für die anschließende Auswertung verwendet werden. Dabei wurden Grenzwerte $\beta_{min} = 0.15$ und $\beta_{max} = 0.95$ im normierten OD-Raum als untere und obere Schranke festgelegt, um nicht gefärbte und chemisch gesättigte Pixel auszuschließen. 
\begin{figure}
\subfloat[Originalbild]{
\includegraphics[width=0.45\textwidth]
{pics/Methoden/mac_original}\label{fig:mac_orig}}
\quad
\subfloat[Relevante Pixel]{
\includegraphics[width=0.45\textwidth]
{pics/Methoden/mac_bin}\label{fig:mac_bin}}
\caption[Macenko: Identifizierung gefärbter Pixel]{Macenko: Die Grafik zeigt links das Originalbild, im Binärbild rechts sind die identifizierten relevanten Pixel in weiß dargestellt. \label{fig:mac_orig_bin}}
\end{figure}  
Für die relevanten Pixel wurde im Anschluss die Kovarianzmatrix anhand von Formel \ref{equ:covar} berechnet.
\begin{equation}
\label{equ:covar}
\mathbf{C} = \frac{1}{N-1}\sum_{i = 1}^N (\vec{x} - \vec{\mu})\cdot(\vec{x} - \vec{mu})^T
\end{equation}

Die Bestimmung der ersten beiden Hauptachsen erfolgte mittels Singulärwertzerlegung (SVD) der Kovarianzmatrix. Dadurch wird diese in zwei orthogonale Matrizen $\mathbf{U}$ und $\mathbf{V}$ sowie die Matrix $\Sigma$, welche auf der Hauptachse die Singulärwerte der Matrix enthält und ansonsten Null ist, zerlegt. Die Singulärwerte sind außerdem entlang der Hauptachse der Größe nach geordnet, wobei der größte Wert an der Stelle $\mathbf{\Sigma}_{0,0}$ steht. Die beiden Hauptachsen, welche mit den beiden größten Eigenwerten korrespondieren, sind aus diesem Grund die beiden ersten Spaltenvektoren in $\mathbf{U}$. 
\begin{equation}\label{equ:svd}
\text{SVD: }\mathbf{A} = \mathbf{U}\mathbf{\Sigma}\mathbf{V}^T
\end{equation}
In der Folge wurden die Pixelvektoren auf die Ebene projiziert, welche durch die beiden Hauptvektoren $\vec{u_1}$ und $\vec{u_2}$ aufgespannt wird. Als nächstem Schritt sollen die projizierten Vektoren normiert werden. Da die Ebene keine Ursprungsebene ist, liegt der normierte Vektor zunächst nicht wieder in der Ebene. Aus diesem Grund wird ein iteratives Verfahren angewendet, bei dem der projizierte Vektor erst normiert wird, in dem durch seine Länge geteilt wird und dieser normierte Vektor dann wiederum auf die Ebene projiziert wird. Dieses Vorgehen wird solange fortgesetzt bis die Änderung kleiner einem $\epsilon$ ist. In Abbildung \ref{fig:norm_scheme} ist das Verfahren anhand des zweidimensionalen Falls vereinfacht dargestellt. Dort wird im Gegensatz zum realen Anwendungsfall ein Punkt auf eine Gerade projiziert und normiert. 
\begin{figure}
\center
\includegraphics[width = 0.95\textwidth]
{pics/Methoden/normalisation_scheme}
\caption[Iteratives Normalisierungsverfahren]{Iteratives Normalisierungsschema: Schwarz dargestellt ist die Gerade auf der Punkt zunächst liegt und am Ende auch wieder liegen soll. Der Einheitskreis, auf dem die normierten Punkte liegen müssen, ist durch die grüne Linie angegeben. In blau dargestellt ist die Normierung in jedem Schritt, rot ist die orthogonale Projektion. Start- und Endpunkt des Verfahrens sind jeweils angegeben.\label{fig:norm_scheme}}
\end{figure}
In der vorliegenden Arbeit waren maximal zwei Iterationen notwendig. Der eingeschlossene Winkel zwischen Pixelvektoren und zweiter Hauptachse wird danach in ein Histogramm eingetragen. Das kumulierte Histogramm erlaubt im nächsten Schritt eine schnelle Ermittlung des stabilen Minimums und Maximums. Als Grenzwert wird $\alpha = 0.01$ verwendet, das heißt es wird jeweils das erste Feld von unten mit $p \geq \alpha$ bzw. von oben mit $p \leq 1-\alpha$ gesucht. Nachdem die jeweiligen Felder identifiziert sind, wird der Mittelwert über alle dort enthaltenen Repräsentanten berechnet. Im Original von Macenko wird der Winkel zur ersten Hauptachse verwendet, im vorliegenden Fall, führt dies jedoch bei Winkeln $\gamma \approx \pi$ zu numerischen Fehlern. Durch die Änderung werden diese Winkel vermieden und das Resultat entspricht einer Verschiebung des Histogramms um $\frac{\pi}{2}$. Für die Bestimmung der Stainvektoren spielt es keine Rolle, zu welcher Achse die Winkel bestimmt werden. Abbildung \ref{fig:mac_proj} zeigt die einzelnen Schritte, von der originalen Punktwolke, über die projizierte Version zur normierten Version für alle relevanten Pixel aus dem Trainingsset. Außerdem ist das zugehörige Histogramm über alle Winkel abgebildet. Die y-Achse gibt hierbei die Wahrscheinlichkeit für die einzelnen Felder an. Die Implementierung des Algorithmus von Macenko erfolgte in Matlab.
\begin{figure}
\subfloat[Originale Punktwolke]{
\includegraphics[width=0.45\textwidth]
{pics/Methoden/mac_notprojected}\label{fig:mac_cloud_orig}}
\quad
\subfloat[Projizierte Punktwolke]{
\includegraphics[width=0.45\textwidth]
{pics/Methoden/mac_projected}\label{fig:mac_cloud_proj}}
\quad
\subfloat[Normalisierte Punktwolke]{
\includegraphics[width= 0.45\textwidth]
{pics/Methoden/mac_normalised}\label{fig:mac_cloud_norm}}
\quad
\subfloat[Histogramm über die Winkel]{
\includegraphics[width = 0.45\textwidth]
{pics/Methoden/mac_histo_angles}\label{fig:mac_histo}}
\caption[Projektion und Winkelhistogramm]{Macenko: $\mathbf{(a)}$ Die originale Punktwolke, $\mathbf{(b)}$ Projizierte Punktwolke auf Ebene der Eigenvektoren. $\mathbf{c}$ Normalisierte Punktwolke. Rot ist jeweils der erste Hauptvektor dargestellt, blau der zweite. $\mathbf{(d)}$ Das Histogramm über die Winkel mit dem zweiten Hauptvektor. \label{fig:mac_proj}}
\end{figure}  

\section{Verfahren nach Khan}\label{sec:implementierung_khan}
Für die Umsetzung des von \citeeig{khan2014nonlinear} vorgeschlagenen Algorithmus zur Klassifikation der einzelnen Pixel wurde zunächst aus einem Set aus Trainingsbildern ein Octree gebildet, der die vorkommenden Farben möglichst gut abbildet. \citeauthor{khan2014nonlinear} fassen den Octree solange zusammen, bis dieser noch genau 255 Blattknoten hat. Rechnerisch ist dies jedoch nicht möglich. Da in jedem Unterteilungsschritt ein Blatt durch acht neue ersetzt wird, bzw. beim Zusammenfassen acht Blätter durch den jeweiligen Elternknoten ersetzt werden, folgt die Zahl der Blattknoten $x$ folgender Logik:  $x = 1+i*7, i \in \mathbb{N}$. Aus diesem Grund wurde statt 255 das nächst kleinere gültige Ziel 253 verwendet. Die auf diese Weise festgelegte Quantisierung wurde nun auf alle Trainingsbilder angewendet und die Merkmalsvektoren wie bei \citeauthor{khan2014nonlinear} berechnet. Problematisch für die vorliegenden Daten war die Definition einer Klassenzugehörigkeit. Als Grundwahrheit verfügbar war für jedes Bild die Region of Interest einer Zelle, welche zudem in Plasma und Kern unterteilt war, sodass ein 3-Klassenproblem $s_n \in \lbrace\text{KERN, PLASMA, HINTERGRUND}\rbrace$ festgelegt wurde. Für ein Pixel welches laut Grundwahrheit nicht zu Kern oder Plasma der jeweiligen Zielzelle im Bild gehört, ist nicht bekannt, ob dieses wirklich Hintergrund zeigt, oder ob es zu einer anderen Zelle gehört. Um eine Zuordnung eines gefärbten Pixels zur Klasse Hintergrund zu vermeiden, wurde ein Clusteringverfahren angewendet, welches das Bild in gefärbte und nicht gefärbte Pixel unterteilt. Dabei wird zunächst der Arcustangens zwischen Blau- und Grünkanal berechnet und im Anschluss ein Grenzwert nach dem Verfahren von Otsu berechnet \cite{otsu1975threshold}. Im daraus resultierenden Binärbild werden mittels morphologischen Operationen wie Closing noch Fehler reduziert \cite{krappe2015dynamic}. Pixel, die im Binärbild als gefärbt markiert sind, jedoch nicht zur Zielzelle gehören, wurden für das Trainieren des Klassifikators ausgeschlossen. Für die Klassifikation wurde eine Support Vector Regression (SVR) aus der Bibliothek OpenCV verwendet. Geeignete Parameter wurden mittels 10-facher Kreuzvalidierung bestimmt. Für den Fall, dass das Problem auf eine Zellart beschränkt wird, können gute Ergebnisse erreicht werden. Für das reale Problem ist die Streuung der Daten innerhalb einer Klasse sehr groß, während der Abstand zwischen den Klassen nicht weiter steigt. Aus diesem Grund war die Zuordnung der Pixel zu einer Klasse in den Tests nicht befriedigend. Um für den folgenden Schritt der Anpassung mittels B-Spline trotzdem die notwendige Zuordnung zu finden, wurde ein alternativer Ansatz entwickelt (siehe Abschnitt \ref{sec:clustering}).


\section{Eigener Workflow}\label{sec:eigener_workflow}

Im den folgenden Abschnitten soll aufgezeigt werden, inwiefern das Vorgehen von \citeauthor{khan2014nonlinear} und \citeauthor{macenko2009method} abgeändert wurde um die aufgetretenen Probleme zu umgehen. Ausgehend von der Color Deconvolution wurden verschiedene Ansätze implementiert um eine Anpassung eines Bildes an eine Referenz zu realisieren. Abbildung \ref{fig:ablaufdiagramm} zeigt eine Gesamtübersicht über die in der Arbeit verfolgten Wege.
\begin{figure}
%\includegraphics[scale=0.7]{pics/Methoden/Workflow_aichinwg}
\caption[Ablaufdiagramm für Farbnormalisierung]{Schematischer Ablauf der implementierten Normalisierungsverfahren.\label{fig:ablaufdiagramm}}
\end{figure}

\subsection[Color Deconvolution]{Color Deconvolution}\label{sec:own_cd}
In nächster Näherung wurden zunächst Stainvektoren für die Färbung nach Giemsa (Methylenblau und Eosin) verwendet, welche von \citeeig{landini2016} nach dem in Abschnitt \ref{sec:color_deconvolution} vorgestellten experimentellen Verfahren ermittelt wurden. Außerdem wurden als Vergleich die Stainvektoren benutzt, die mit Hilfe des von \citeauthor{macenko2009method} eingeführten Verfahrens bestimmt worden sind (siehe Abschnitt \ref{sec:implementierung_macenko}). Für den jeweils fehlenden dritten Vektor, wird u.a. in der Arbeit von Khan angemerkt, dass dieser optimalerweise orthogonal zu den anderen beiden sein soll. Außer im Fall von Einheitsvektoren, würde dieser jedoch negative Komponenten enthalten, was im Modell die Folge hätte, dass die Absorption teilweise negativ wäre. Da dies mit der Realität nicht vereinbar ist, wurden als Lösung zwei verschiedene Ansätze getestet. Die ersten beiden Zeilen der Stainmatrix sind bekannt und \citeauthor{landini2016} berechnet die dritte Zeile der Stainmatrix, in dem er zunächst die Spalten normalisiert, jedoch nur für den Fall dass die euklidische Norm der ersten beiden Komponenten nicht schon über $1.0$ liegt. Tritt dies doch ein, so wird das Element der dritten Zeile auf $0.0$ gesetzt. Im nächsten Schritt wird die Zeile normalisiert und Elemente die gleich $0$ werden zur Fehlerreduktion auf einen Wert $\epsilon = 0.01$ gesetzt. Diese Methode wurde der eigenen Idee gegenübergestellt, bei der zunächst über das Kreuzprodukt ein echt orthogonaler Vektor bestimmt wird. Dabei werden beide  Szenarien abhängig vom Vorzeichen berücksichtigt. Negative Komponenten werden auf $0.0$ gesetzt. Derjenige Vektor, der nach dieser Operation die größere Länge aufweist, wird gewählt und normalisiert und als dritter Stainvektor eingesetzt. Unabhängig von der Wahl des dritten Vektors ist die Approximation für die vorhandenen Daten legitim, da der dritte Kanal für beide Fälle in gefärbten Bereichen keine Information aufweist. In Abbildung \ref{fig:cd_examples} sind Beispiele für die jeweiligen Zerlegungen gezeigt. 
\begin{figure}
\subfloat[Originalbild]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/original}\label{fig:cd1_original}}
\quad
\subfloat[Kanal 1, Giemsa]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor1}\label{fig:cd1_ch1}}
\quad
\subfloat[Kanal 2, Giemsa]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor2}\label{fig:cd1_ch2}}
\quad
\subfloat[Kanal 3, Giemsa, normalisierte Spalten]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor3}\label{fig:cd1_ch31}}
\quad
\subfloat[Kanal 3, Giemsa, ]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor3_orthGiemsa}\label{fig:cd1_ch32}}
\quad
\subfloat[Originalbild]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/original}\label{fig:cd2_original}}
\quad
\subfloat[Kanal 1, Macenko]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor1_macenko}\label{fig:cd2_ch1}}
\quad
\subfloat[Kanal 2, Macenko]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor2_macenko}\label{fig:cd2_ch2}}
\quad
\subfloat[Kanal 3, Macenko, normalisierte Spalten]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor3_macenko}\label{fig:cd2_ch31}}
\quad
\subfloat[Kanal 3, Macenko, orthogonale Stains]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor3_orthMacenko}\label{fig:cd2_ch32}}
\quad
\subfloat[Originalbild]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/original2}\label{fig:cd3_original}}
\quad
\subfloat[Kanal 1, Macenko]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor1_macenko2}\label{fig:cd3_ch1}}
\quad
\subfloat[Kanal 2, Macenko]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor2_macenko2}\label{fig:cd3_ch2}}
\quad
\subfloat[Kanal 3, Macenko, normalisierte Spalten]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor3_macenko2}\label{fig:cd3_ch31}}
\quad
\subfloat[Kanal 3, Macenko, orthogonale Stains]{
\includegraphics[width=0.15\textwidth]
{pics/Methoden/CHColor3_orthMacenko2}\label{fig:cd3_ch32}}
\caption[Color Deconvolution]{Verschiedene Ansätze für die Color Deconvolution. \textbf{(a-e)} Verwendung der experimentell gefundenen Stains, \textbf{(f-o)} Verwendung Stains bestimmt nach Macenko (\ref{sec:implementierung_macenko}). \label{fig:cd_examples}}
\end{figure} 
Eine Idee, die Zerlegung bildspezifisch zu optimieren, ist die Definition einer Zielfunktion für ein Optimierungsproblem, wobei als Initialstelle die Giemsa-Farbstoffe dienen können. Die Funktion ist von vier Parametern abhängig, nämlich den jeweils ersten beiden Elementen der Farbe repräsentierenden Stainvektoren. Dies ist nur möglich, falls nur zwei Grundfarbstoffe verwendet werden, da ansonsten der dritte Vektor nicht in Abhängigkeit der ersten beiden berechnet werden kann. Folgende Eigenschaften der Zerlegung wurden als Komponenten der Zielfunktion festgelegt:
\begin{itemize}
\item{Energie Kanal 3: In gefärbten Bereichen sollte der dritte Kanal weiß sein, da die Farbinformation aus den beiden verwendeten Farbstoffen zusammengesetzt ist.}
\item{Abstand zur Hauptebene: Angelehnt an das Verfahren nach Macenko, wurde ein Maß eingeführt, dass den Abstand für gefärbte Pixel zur Hauptebene, welche durch die ersten beiden Stainvektoren definiert wird, verringert. Einfluss darauf, wie die beiden Vektoren innerhalb dieser Ebene liegen, hat dieses Maß keinen.}
\item{Der Winkel zwischen den beiden ersten Stainvektoren soll möglichst klein sein, gleichzeitig aber eine möglichst große Zahl Pixel einschließen. }
\end{itemize}
Zur Lösung des Optimierungsproblems wurde ein Gradientenabstiegsverfahren aus OpenCV eingesetzt. 
\subsection{Bildclustering}\label{sec:clustering}
Um die Farbnormalisierung nach Khan durchzuführen, ist eine Zuordnung der Pixel in die Klassen "Gefärbt", "Hintergrund" und "Sonstiges" notwendig. Bei Khan wird diese durch einen Klassifikator realisiert, der für die vorliegenden Daten jedoch nicht geeignet war und schlechte Resultate lieferte. Aus diesem Grund wurde eine eigene Methode zur Identifikation der Cluster entwickelt. Zunächst werden mit Hilfe des Arcustangens aus Blau- und Grünkanal und einer Schwellwertbestimmung nach Otsu \cite{otsu1975threshold} gefärbte Pixel identifiziert. Für den Hintergrund wird das Grauwertbild betrachtet. Die Histogramme weisen ein ausgeprägtes Maximum im Bereich hoher Intensitäten ($ > 200$) auf, wodurch der Hintergrund gut definiert ist. Der Schwellwert wird als erstes lokales Minimum unterhalb des Maximums festgelegt, wobei sowohl für die Bestimmung des Maximums als auch des Minimums ein gefiltertes Histogramm verwendet wird. Außerdem wird eine Minimaldistanz zwischen Maximum und Minimum eingeführt. Dadurch wird im Fall von zwei eng zusammenliegenden Maximumsspitzen vermieden, dass Teile des gesuchten Bereichs nicht erfasst werden. Der Bereich "Sonstiges", in den vor allem Erythrozyten fallen, grenzt sich deutlich vom Hintergrund ab. Deswegen ist die Annahme, dass die Intensitätsdifferenz zwischen dem Maximum des Hintergrunds und Pixeln die in "Sonstiges" fallen mindestens fünf betragen sollte, valide. Der Fall eines sehr homogenen Hintergrund mit schmaler Spitze im Histogramm spielt eine untergeordnete Rolle, da die Intensitäten in "Sonstiges" stark streuen und ein Fehler des Schwellwerts $<5$ vernachlässigbar ist. Es gibt Fälle in denen kein Hintergrund zu sehen ist, bzw. dieser aufgrund leichter Färbung nicht mehr klar abgrenzbar ist. In diesen Fällen ist das Maximum dunkler als normal. Empirisch wurde der Bereich $ > 200$ festgelegt, für das ein gültiger Hintergrund gefunden werden kann. Für den Fall, dass das Maximum darunter liegt, wird für dieses Bild kein Hintergrund festgelegt. Dies hat Auswirkungen auf die Berechnung des Bsplines, da keine Merkmale für das Cluster vorhanden sind. Der Umgang mit diesem Fall wird in Abschnitt \ref{sec:bspline} beschrieben. 

Nach der Bestimmung der Bereiche "Hintergrund" und "Gefärbt" ergibt sich "Sonstiges" aus den bisher nicht festgelegten Pixeln. Vorausgesetzt wird jedoch, dass diese Pixel nach der Color Deconvolution im dritten Kanal nicht weiß sind, da dies Eigenschaften des gefärbten Bereichs bzw. eines sehr hellen Hintergrunds wären. Wichtig ist diese Einschränkung u.a. wenn die Farbeigenschaft von hellerem Plasma durch den Arcustangens nicht komplett erfasst wird. Dadurch wird verhindert, dass ein solcher Bereich anschließend "Sonstiges" zugeordnet wird. In Abbildung \ref{fig:clustering} sind die einzelnen Zwischenschritte die das Clustering betreffen dargestellt, sowie das Endresultat.   
\begin{figure}
\subfloat[Originalbild]{
\includegraphics[width=0.3\textwidth]
{pics/Methoden/original_target}\label{fig:cluster_original}}
\quad
\subfloat[Arcustangens Blau und Grün]{
\includegraphics[width=0.3\textwidth]
{pics/Methoden/arctan}\label{fig:seg_arctan}}
\quad
\subfloat[Binärbild gefärbte Bereiche]{
\includegraphics[width=0.3\textwidth]
{pics/Methoden/bin_stained}\label{fig:seg_bin_stained}}
\quad
\subfloat[Grauwertbild]{
\includegraphics[width=0.3\textwidth]
{pics/Methoden/gray}\label{fig:seg_gray}}
\quad
\subfloat[Histogramm Grauwertbild]{
\includegraphics[width=0.3\textwidth]
{pics/Methoden/histogram}\label{fig:seg_histogram}}
\quad
\subfloat[Gefundene Cluster]{
\includegraphics[width=0.3\textwidth]
{pics/Methoden/segmented}\label{fig:seg_seg}}
\caption[Eigene Segmentierung]{Die Abbildung zeigt relevante Zwischenergebnisse für den Segmentierungsansatz. $(\mathbf{(c)}$ Weißer Bereich signalisiert gefärbten Bereich im Original. $\mathbf{(e)}$ Rote Linie markiert den gesuchten Schwellwert. Höhere Intensitäten werden dem Hintergrund zugeordnet. $\mathbf{(f)}$ Ergebnis: Weiß $\equiv$ Gefärbt, helles Grau $\equiv$ Sonstiges, dunkles Grau $\equiv$ Hintergrund, Schwarz $\equiv$ Keine Zuordnung\label{fig:clustering}}
\end{figure} 

\subsection{Anpassung}\label{sec:anpassung}

Wie in Kapitel \ref{sec:stand_der_technik} beschrieben, gibt es nach der Color Deconvolution verschiedene Möglichkeiten für die eigentliche Anpassung der Histogramme. Im Folgenden werden die Details der verschiedenen getesteten Ansätze beschrieben. 

\subsubsection{B-Spline}\label{sec:bspline}
Die Implementierung der B-Spline-Berechnung weist viele Parallelen, aber auch Abweichungen gegenüber der von Khan (Abschnitt \ref{sec:khan}) auf. Als Kontrollpunkte dienen die gleichen Merkmale der Histogramme, die in einem Kanal für jedes Cluster gebildet werden. Die Interpolation an den Sättigungsstellen ist dagegen im Gegensatz zum Original unterschiedlich gesichert. Bei Khan gibt es mehrere zusätzliche Kontrollpunkte, in der vorliegenden Arbeit gibt es genau zwei. Dabei liegt einer am unteren, der andere am oberen Ende. Dass diese Punkte trotzdem interpoliert werden, liegt an der Anpassung des Knotenvektors, wo den entsprechenden Knoten eine Vielfachheit $n$ zugewiesen wird. Gleichzeitig entspricht $n$ auch dem Grad des B-Splines. Die verbleibenden Knoten werden gleichmäßig über das Parameterintervall verteilt. Eine optimale Schätzung wie bei \citeauthor{khan2014nonlinear} wird dabei nicht durchgeführt, allerdings ist der Grad des B-Splines und damit auch die Länge des Knotenvektors variabel. Um am Ende eine sinnvolle und eindeutige Zuordnung eines Intensitätswerts im Eingangsbild zu einem angepasstem Wert zu erhalten ist es notwendig, die Kontrollpunkte anhand der Komponente, die durch das Eingangsbild bestimmt wird, zu sortieren. Abbildung \ref{fig:histograms_regions} zeigt für das Beispiel aus Abbildung \ref{fig:cluster_original} die nach Bildregion getrennten Histogramme. In Abbildung \ref{fig:bsplines_own} sind die auf den ersten Kanal bezogenen B-Splines für die Anpassung des gleichen Bildes auf ein Referenzbild zu sehen. Die Kurven unterscheiden sich dabei hinsichtlich des verwendeten Grads $n$.

\begin{figure}

\includegraphics[width=0.7\textwidth]
{pics/Methoden/bspline_histograms}
\caption[Histogramme der verschiedenen Regionen]{Die Abbildung zeigt die Histogramme des ersten Farbkanals nach Color Deconvolution von Bild \ref{fig:seg_original}. Die rote Kurve gehört dabei zum Hintergrund, blau zu Sonstiges und die türkise Kurve deckt den gefärbten Bereich im Bild ab. Die einzelnen Histogramme wurden so normiert, dass die Summe der Wahrscheinlichkeiten pro Histogramm eins entspricht.\label{fig:histograms_regions}}
\end{figure}

\begin{figure}
\center
\subfloat[Original]{
\includegraphics[width=0.3\textwidth]
{pics/Methoden/original_target}\label{fig:bspline_orig}}
\quad\quad\quad\quad\quad\quad\quad\quad
\subfloat[Referenz]{
\includegraphics[width=0.3\textwidth]
{pics/Methoden/bspline_target}\label{fig:bspline_ref}}
\quad
\subfloat[Kompletter B-Spline, Grad 4]{
\includegraphics[width=0.48\textwidth]
{pics/Methoden/bspline_komplett_4}\label{fig:bspline_komp_4}}
\quad
\subfloat[Kompletter B-Spline, Grad 8]{
\includegraphics[width=0.48\textwidth]
{pics/Methoden/bspline_komplett_8}\label{fig:bspline_komp_8}}
\quad
\subfloat[B-Spline vergrößert, Grad 4]{
\includegraphics[width=0.48\textwidth]
{pics/Methoden/bspline_sub_4}\label{fig:bspline_sub_4}}
\quad
\subfloat[B-Spline vergrößert, Grad 8]{
\includegraphics[width=0.48\textwidth]
{pics/Methoden/bspline_sub_8}\label{fig:bspline_sub_8}}
\caption[Eigene Bsplines zur Farbnormalisierung]{Die Abbildung $\mathbf{(a)}$ zeigt ein Originalbild und $\mathbf{(b)}$ das Referenzbild. $\mathbf{(c)}$ und $\mathbf{(d)}$ zeigen den kompletten Verlauf der Bsplines mit allen Kontrollpunkten für Grad $n = 4$ bzw. $ n = 8$. $\mathbf{(e)}$ und $\mathbf{(f)}$ zeigen die Verläufe im Bereich der histogrammbasierten Kontrollpunkte, d.h. die Sättigungsstellen sind hier nicht zu sehen.  \label{fig:bsplines_own}}
\end{figure}

Wie bereits in Abschnitt \ref{sec:clustering} beschrieben, ist es möglich, dass in einem Bild ein Cluster nicht enthalten ist bzw. nicht automatisch identifiziert werden kann. In diesem Fall werden die fehlenden Merkmale als gleich den entsprechenden Merkmalen aus der Referenz festgelegt. Die daraus resultierenden Kontrollpunkte liegen deshalb exakt auf der Winkelhalbierenden.
 
\subsubsection{Mittelwert und Standardabweichung}\label{sec:mean_std}
Wie in Kapitel \ref{sec:reinhard} beschrieben, können Histogramme durch eine Übertragung der statistischen Eigenschaften Mittelwert und Standardabweichung angepasst werden. Reinhard normierte dabei im $l\alpha\beta$-Farbraum, mit der Argumentation, dass hier stark dekorrelierte Kanäle vorliegen. Eine weitere Möglichkeit besteht darin, als Farbraumtransformation eine Color Deconvolution zu verwenden und in diesen getrennten Kanälen, die Anpassung durchzuführen. Die Beschreibung der relevanten Bildinformationen gelingt durch die Berücksichtigung der zugrundeliegenden chemischen Prozesse besser, was beim Prozess der Farbnormalisierung Vorteile bieten sollte. 

\subsubsection{Skalierung}\label{sec:skalierung}
Eine Skalierung der Histogramme fordert implizit, dass das Maximum der einzelnen Farbstoffe über verschiedene Zellbilder gleich ist. Diese Annahme kann so zwar nicht getroffen werden, jedoch kann bei geschickter Wahl des Zielmaximums der Kontrast so beeinflusst werden, dass sich Vorteile für die spätere Segmentierung ergeben. Eine Skalierung erfolgte in der Implementierung für diese Arbeit nur für die ersten beiden Kanäle, also denjenigen, die auch Farbinformationen tragen. Das Maximum im dritten Kanal ist stark abhängig vom Erscheinungsbild der Erythrozyten aber auch von Verunreinigungen. Eine Normierung des dritten Kanals auf ein Pseudomaximum ist aus diesem Grund nicht zielführend, wenn es um eine Angleichung des Hintergrunds geht. 

\subsection{Auswahl Referenzbild}\label{sec:auswahl_target}

Erste Versuche zeigten, dass ein einzelnes Referenzbild nicht ausreicht, die Vielfältigkeit der Daten abzubilden. Aus diesem Grund wurde manuell ein Set aus 15 Bildern zusammengestellt, welches zum einen möglichst viele verschiedene Ausprägungen, sowie für die Segmentierung geeignete Bilder enthält. Nach Sichtung der Segmentierungsresultate für die Anpassung an die Einzelbilder, konnte die Anzahl der Referenzbilder noch weiter reduziert werden, indem diejenigen Bilder ausgewählt wurden, die hier die besten Ergebnisse lieferten. Für die Anpassung mittels B-Spline wurden auf diese Art die Sets 4-6 zusammengesetzt, für die Anpassung von Mittelwert und Standardabweichung Set 7 (siehe Anhang \ref{app:reference}). Für die Wahl der Referenz wurden unterschiedliche Konzepte entwickelt. Eine Möglichkeit besteht darin, eine Art mittleres Referenzbild zu berechnen, indem für jedes Merkmal, der Mittelwert aller korrespondierenden Merkmale der Referenzbilder gewählt wird. Eine Abwandlung hierzu ist es, den Median anstelle des Mittelwerts zu verwenden, wodurch Ausreißer kein Gewicht bekommen. In beiden Fällen bleiben die Referenzmerkmale für alle zu normalisierenden Bilder gleich. Eine andere Möglichkeit ist es für jedes Bild eine hinsichtlich der Merkmale möglichst ähnliche Referenz auszuwählen. Dadurch ist die Gefahr einer Verfälschung der Bildinformationen am wenigsten gegeben, der Grad der Anpassung über ein ganzes Set hinweg ist jedoch auch geringer. 

\section[Segmentierung]{Segmentierung}\label{sec:segmentierung}
Eine Automatisierung der Differenzialzählung erfordert eine stabile Segmentierung der einzelnen Zellen. Im Folgenden wird zunächst der verwendete Algorithmus vorgestellt, im Anschluss die Methodik der Evaluierung. 

\subsection{Algorithmus}\label{sec:seg_algo}
\citeauthor{krappe2015dynamic} stellen in ihren Arbeiten \cite{krappe2014lokalisierung} und \cite{krappe2015dynamic} hierzu ein zweistufiges Verfahren vor, bei dem im ersten Schritt die Zellzentren detektiert werden sollen. Es wird ein Grauwertbild mit Hilfe eines gewichteten Quotienten von Grün- und Blaukanal generiert. Otsu-Thresholding \cite{otsu1975threshold} führt im Anschluss zu einem Binärbild, in dem durch Zählen der schwarzen und weißen Pixel entschieden wird, ob das Bild viele oder wenige gefärbte Flächen enthält, wovon das weitere Vorgehen abhängt. Ist wenig Vordergrund enthalten, so werden mit Hilfe morphologischer Operatoren Löcher im innerhalb weißer Flächen aufgefüllt. Für die Ermittlung potentieller Zellzentren, wird eine Wasserscheidentransformation auf dem gaußgefilterten oben beschriebenen Grauwertbild durchgeführt. Regionen welche eine Größe von 2500 Pixeln überschreiten, werden in eine Graphendarstellung umgewandelt. Falls gefundene Zentren eine euklidische Distanz von weniger als 70 Pixeln aufweisen, so wird davon ausgegangen, dass diese Knoten auf die gleiche Zelle verweisen, weshalb sie durch einen neuen Knoten ersetzt werden, der den Mittelwert repräsentiert. Dieser Schritt ist in Abbildung \ref{fig:cell_centers} dargestellt.
\begin{figure}[htb]
\subfloat[Vor Korrektur: eine Zelle wird durch zwei Zentren beschrieben]{
\includegraphics[width=0.45\textwidth]
{pics/Grundlagen/centers_uncorrected}\label{fig:seg_uncorrected}}
\quad
\subfloat[Nach Korrektur: Jede Zelle mit nur einem Zentrum]{
\includegraphics[width=0.45\textwidth]
{pics/Grundlagen/centers_corrected}\label{fig:seg_corrected}}
\quad
\caption[Identifizierung Zellzentren]{Im Korrekturschritt werden Zentren mit geringer Distanz, grün markiert in \textbf{(a)}, zu einem Zentrum zusammengefügt \textbf{(b)} \cite{krappe2014lokalisierung}. \label{fig:cell_centers}}
\end{figure} 
Hat das Bild dagegen einen hohen Vordergrundanteil, so wird eine Hintergrundkorrektur durchgeführt, bei der dieser durch ein 2D-Polynom dritten Grades approximiert wird. Der Vordergrund wird zunächst mit Hilfe eines Mittelwertfilters geschätzt und dann unter Verwendung des "Fast Marching"-Algorithmus konkretisiert. In der Folge werden homogene Regionen mit dem "Color Structure Code" extrahiert und als geordneter Graph dargestellt. Die Blätter dieses Graphen sind die potentiellen Zellzentren, die anhand des gleichen Verfahrens wie im Fall mit viel Vordergrund korrigiert werden. 
Um in der eigentlichen Segmentierung den äußeren Rand und die Grenze zwischen Zellkern und Zellplasma zu bestimmen, wird für jede Zelle eine Polartransformation mit dem im vorherigen Schritt gefundenen Zentrum durchgeführt. Es wird eine zu minimierende Kostenfunktion eingeführt, die aus sechs Komponenten besteht:
\begin{itemize}
\item{Gradient des gaussgefilterten Farbbild}
\item{Radius mit spezifischem minimalen und maximalem Radius}
\item{Gewichtung anhand Arcustangens von Blau- und Grünkanal}
\item{Distanztransformation bzgl. Vordergrund: Hohe Werte für weit von nächster Zelle entfernte Pixel}
\item{Distanztransformation bzgl. Hintergrund: Hohe Werte für Pixel im Zentrum einer Zelle}
\item{SLIC Superpixel + Distanzmaß als Gewichtung}
\end{itemize}

Der Weg im Kostenbild von 0-6$\pi$ soll minimiert werden. Durch die dreifache Wiederholung wird verhindert, dass Anfang und Endpunkt des Weges nicht übereinstimmen. Dies hätte zur Folge, dass die Segmentierung im späteren Bild nicht geschlossen ist und einen Sprung aufweist. Die inverse Polartransformation überführt die segmentierende Linie zurück in den ursprünglichen Bildraum. Abbildung \ref{fig:seg_outer_borders} soll die einzelnen Schritte anhand eines Beispiels verdeutlichen.
\begin{figure}[htb]
\center
\subfloat[Originalbild]{
\includegraphics[width=0.35\textwidth]
{pics/Grundlagen/seg_orig}\label{fig:seg_original}}
\quad
\subfloat[Polartransformiertes Original, dreifach aneinandergehängt]{
\includegraphics[width = 0.9\textwidth]{pics/Grundlagen/seg_polar}\label{fig:seg_polartransform}}
\quad
\subfloat[Kostenfunktion]{
\includegraphics[width = 0.9\textwidth]{pics/Grundlagen/seg_function}\label{fig:seg_costfunction}}
\quad
\subfloat[Weg mit minimalen Kosten]{
\includegraphics[width = 0.9\textwidth]{pics/Grundlagen/seg_min}\label{fig:seg_min}}
\quad
\subfloat[Hervorgehobenes Ergebnis Segmentierung]{
\includegraphics[width=0.35\textwidth]
{pics/Grundlagen/seg_seg}\label{fig:seg_seg_autom}}
\quad
\caption[Segmentierung mittels Polartransformation]{$\mathbf{(a)}$ Originalbild; $\mathbf{(b)}$ Polartransformation mit Zentrum der Zelle als Nullpunkt; $\mathbf{(c)}$ Kostenfunktion, wobei die Kosten in den dunklen Bereichen minimal sind; $\mathbf{(d)}$ Auswertung der Kostenfunktion: Grüne Linie entspricht Weg mit den geringsten Kosten; $\mathbf{(e)}$ Inverse Polartransformation, heller Bereich entspricht der segmentierten Zelle \cite{krappe2015dynamic} \label{fig:seg_outer_borders}}
\end{figure}
Die Unterscheidung zwischen Plasma und Zellkern wird wieder auf dem Graubild realisiert, welches durch den Arcustangens von Blau und Grün gebildet wird. Dafür wird das Histogramm der Pixel, die innerhalb der zuvor segmentierten Zelle liegen, bestimmt. Mit Hilfe der Grenzwertbestimmung von Otsu wird das Histogramm und dadurch auch das Bild in zwei verschiedene Bereiche aufgeteilt.

\subsection{Verfahren zur Evaluierung}\label{sec:seg_eval}

Für die Evaluation der Segmentierung, wurde der automatische Algorithmus mit den als Grundwahrheit dienenden manuell bestimmten Daten verglichen. Das verwendete Maß ist dabei eine Kombination aus Unter- bzw. Übersegmentierung und dem AOM-Kriterium, welches den Überlappungsbereich beschreibt \cite{dominguez2007improved}. 

\noindent AOM-Kriterium:
\begin{equation}
Q_1 = \frac{|T\cap A|}{|T\cup A|}
\end{equation}
Übersegmentierung:
\begin{equation}
Q_2 = \frac{|T\setminus (A\cap T)|}{|T|}
\end{equation}
Untersegmentierung:
\begin{equation}
Q_3 = \frac{|A\setminus (A\cap T)|}{|A|}
\end{equation}

Soll die Segmentierung der Zelle als ganzem betrachtet werden, so ist $A$ die Menge aller Punkte, welche laut automatischer Segmentierung zur Zelle gehören. $T$ steht für die äquivalente Menge entsprechend der Grundwahrheit. Für eine Auswertung, welche zudem die Aufteilung zwischen Zellkern- und Plasma berücksichtigt, dient der Nucleus als Region of Interest.
  
\section[Klassifizierung]{Klassifizierung}\label{sec:klassifizierung}
Der zweite wichtige Baustein für eine automatisierte Differentialzählung  ist die Zellklassifikation, welche der Segmentierung nachfolgt. Die hierfür angewandte Klassifikationskette wird im folgenden Abschnitt beschrieben. Im Anschluss wird auf Besonderheiten bei der Auswertung sowie verwendete Maße eingegangen.

\subsection{Algorithmus}\label{sec:klass_algo}
Der angewandte Klassifikationsalgorithmus, bei dem jede Zelle einer von 16 Klassen zugeordnet werden soll, wurde von \citeeig{krappe2016automated} entwickelt. Hierbei wird das Wissen über die Hematopoese genutzt und in Form eines hierarchischen Baummodell nachgebildet, wie in Abbildung \ref{fig:classification_tree} dargestellt.
\begin{figure}
\center
\includegraphics[width = \textwidth]{pics/Methoden/Hierarchy}
\caption[Hierarchisches Baummodell für die Klassifikation]{Darstellung des hierarchischen Baummodell, das die Hematopoese annähert\label{fig:classification_tree}}
\end{figure} 
Die für die Klassifikation verwendeten Merkmale teilen sich in Form, Textur und Farbe auf. Bei der Form spielen die gesamte Fläche, das Verhältnis aus Kern und Plasma, Konturmerkmale, Zernike Momente, normalisierte zentrale Momente, normalisierte Merkmale des Radius, Formfaktoren und Anzahl der Kernsegmente eine Rolle. Die Textur wird durch Local Binary Patterns, Grauwertmatrizen, Merkmale basierend auf Summen- und Differenzhistogrammen, farbbasierte Texturmerkmale, Charakterisierung von Heterogenität und Granularität, statistische Merkmale basierend auf Geometrie und Lauflängen, Texturmerkmale, die visuelle Eigenschaften von Oberflächen charakterisieren, und die fraktale Dimension beschrieben. Zur Beschreibung der Farbinformationen kommen im RGB-Raum statistische Merkmale der Histogramme sowie zentrale Momente zum Einsatz. Im HSV-Farbraum werden neben den zentralen auch noch andere Momente verwendet. Die extrahierten Merkmale werden mittels z-Transformation normalisiert.

In jedem Knoten des Baummodells wird ein "Einer-gegen-Alle"-Ansatz verwendet. Außerdem werden während des Lernprozess für jeden Knoten 100 Merkmale so ausgewählt, dass der Informationsgehalt möglichst groß wird, bei gleichzeitig geringer Redundanz. Von diesen 100 Merkmalen, werden im Anschluss mittels Merkmalsselektion die besten ausgewählt um eine Support Vector Machine (SVM) zu trainieren. 

\subsection{Verfahren zur Evaluierung}\label{sec:klass_eval}
Für die Evaluierung der Klassifikation spielt die Natur des Problems eine wichtige Rolle. Es ist aus medizinischer Sicht normal und tolerabel, dass die Unterscheidung zwischen ähnlichen Zellklassen bzw. Zellen unterschiedlichen Reifegrads oft nicht klar und deutlich erkennbar ist. Aus diesem Grund werden alle Maße in der Evaluation sowohl für die exakte Klasse, als auch unter Einbeziehung der Toleranz angegeben. Für die Auswertung werden Vertauschungsmatrizen, Trefferquote ("accuracy", Gleichung \ref{equ:acc}) und Genauigkeit ("precision", Gleichung \ref{equ:prec}) verglichen.

Für jede Klasse gibt es Kandidaten, die der Klasse angehören und richtig klassifiziert werden ($TP$), bzw. falsch zugeordnet werden ($FN$). Außerdem gibt es die Möglichkeit, dass der Kandidat der Klasse nicht angehört und ihr auch nicht zugeordnet wird ($TN$). Für den Fall dass die Klasse doch vorausgesagt wird, ist er $FP$.
 
\begin{equation}\label{equ:acc}
Accuracy = \frac{TP}{TP + FN}
\end{equation}
\begin{equation}\label{equ:prec}
Precision = \frac{TP}{TP + FP}
\end{equation}

Für Gleichung \ref{equ:prec} kann der Fall eintreten, dass durch 0 geteilt wird, falls einer Klasse im Klassifikationsschritt kein Kandidat zugeordnet wird. In diesem Fall wird die Genauigkeit auf 0 gesetzt. 
  
In einer Vertauschungsmatrix sind all diese Informationen enthalten. Die Spalten bezeichnen jeweils die wahre Klasse, während die Zeilen die vorhergesagte Klasse erkennen lassen. 
Die allgemeine Trefferquote gibt das Verhältnis aus korrekt klassifizierten Zellen und der Gesamtzahl wieder. Für die allgemeine Genauigkeit eines Klassifikators wurde der Mittelwert über die Genauigkeiten der einzelnen Klassen gebildet. 
 