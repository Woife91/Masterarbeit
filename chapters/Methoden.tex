\chapter[Methoden]{Methoden}\label{sec:methoden}

\section{Implementierung Khan und Macenko}\label{sec:implementierung_khan_macenko}

\section{Eigener Workflow}\label{sec:eigener_workflow}

Im den folgenden Abschnitten soll aufgezeigt werden, inwiefern das Vorgehen von \citeauthor{khan2014nonlinear} und \citeauthor{macenko2009method} abgeändert wurde um die aufgetretenen Probleme zu umgehen.

\subsection[Eigene Color Deconvolution]{Eigene Color Deconvolution}\label{sec:own_cd}
In nächster Näherung wurden Stainvektoren für die Färbung nach Giemsa (Methylenblau und Eosin) verwendet, welche von \citeeig{landini2016} nach dem in Abschnitt \ref{sec:stains_färbung} vorgestellten experimentellen Verfahren ermittelt wurden. Für den fehlenden dritten Vektor, wird u.a. in der Arbeit von Khan angemerkt, dass dieser optimalerweise orthogonal zu den anderen beiden sein soll. Außer im Fall von Einheitsvektoren, würde dieser jedoch negative Komponenten enthalten, was im Modell die Folge hätte, dass die Absorption teilweise negativ wäre. Als Lösung wurden zwei verschiedene Ansätze getestet. Die ersten beiden Zeilen der Stainmatrix sind bekannt und \citeauthor{landini2016} berechnet die dritte Zeile der Stainmatrix, in dem er zunächst die Spalten normalisiert, für den Fall dass die ersten beiden Komponenten nicht schon über $1.0$ liegen. Tritt dies doch ein, so wird das Element der dritten Zeile auf $0.0$ gesetzt. Im nächsten Schritt wird die Zeile normalisiert und Elemente die gleich $0$ werden zur Fehlerreduktion auf einen Wert $\epsilon = 0.01$ gesetzt. Diese Methode wurde der eigenen Idee gegenübergestellt, bei der zunächst über das Kreuzprodukt ein echt orthogonaler Vektor bestimmt wird. Dabei werden beide  Szenarien abhängig vom Vorzeichen berücksichtigt. Negative Komponenten werden auf $0.0$ gesetzt. Derjenige Vektor der nach dieser Operation die größere Länge aufweist, wird gewählt und normalisiert und als dritter Stainvektor eingesetzt. Unabhängig von der Wahl des dritten Vektors ist die Approximation für die vorhandenen Daten legitim, da der dritte Kanal für beide Fälle in gefärbten Bereichen keine Information aufweist.
Eine Idee, die Zerlegung bildspezifisch zu optimieren, ist die Definition einer Zielfunktion für ein Optimierungsproblem, wobei als Initialstelle die Giemsa-Farbstoffe dienen können. Die Funktion ist von vier Parametern abhängig, nämlich den jeweils ersten beiden Elementen der Farbe repräsentierenden Stainvektoren. Dies ist nur möglich, falls nur zwei Grundfarbstoffe verwendet werden, da ansonsten der dritte Vektor nicht in Abhängigkeit der ersten beiden berechnet werden kann. Folgende Eigenschaften der Zerlegung wurden als mögliche Komponenten der Zielfunktion identifiziert:
\begin{itemize}
\item{Entropie in Kanal 3: Der dritte Kanal soll vor allem den Hintergrund repräsentieren, welcher keine relevanten Informationen beinhaltet. Die Entropie dient als Maß für den Informationsgehalt einer Quelle}
\item{Energie Kanal 3: Ähnlich wie im ersten Punkt geht es hierbei darum, der nicht farbrelevanten Komponente eine möglichst untergeordnete Rolle zuzuordnen}
\item{Abstand zur Hauptebene: Angelehnt an Macenko, wurde ein Maß eingeführt, dass den Abstand für gefärbte Pixel zur Hauptebene, welche durch die ersten beiden Stainvektoren definiert wird, verringert. Einfluss darauf, wie die beiden Vektoren innerhalb dieser Ebene liegen, hat dieses Maß keinen.}

\end{itemize}
\subsection{Bildclustering}\label{sec:clustering}

Um die Farbnormalisierung nach Khan durchzuführen, ist eine Zuordnung der Pixel in die Klassen "Gefärbt", "Hintergrund" und "Anderes" notwendig. Bei Khan wird diese durch einen Klassifikator realisiert, der für die vorliegenden Daten jedoch nicht geeignet war und schlechte Resultate lieferte. Aus diesem Grund wurde eine eigene Methode zur Identifikation der Cluster entwickelt. Zunächst werden mit Hilfe des Arcustangens aus Blau- und Grünkanal und einer Schwellwertbestimmung nach Otsu gefärbte Pixel identifiziert. Für den Hintergrund wird das Grauwertbild betrachtet. Die Histogramme weisen ein ausgeprägtes Maximum im Bereich hoher Intensitäten ($ > 200$)auf, wodurch der Hintergrund gut definiert ist. Der Schwellwert wird als erstes lokales Minimum unterhalb des Maximums festgelegt, wobei sowohl für die Bestimmung des Maximums als auch des Minimums ein gefiltertes Bild verwendet wird. Außerdem wird eine Minimaldistanz zwischen Maximum und Minimum eingeführt. Dadurch wird im Fall von zwei eng zusammenliegenden Maximumsspitzen vermieden, dass Teile des gesuchten Bereichs nicht erfasst werden. Der Bereich "Anderes", in den vor allem Erythrozyten fallen, grenzt sich deutlich vom Hintergrund ab, weswegen die Annahme, dass die Intensitätsdifferenz zwischen dem Maximum des Hintergrunds und Pixeln die in "Anderes" fallen mindestens fünf betragen sollte, valide ist. Der Fall eines sehr homogenen Hintergrund mit schmaler Spitze im Histogramm spielt eine untergeordnete Rolle, da die Intensitäten in "Anderes" stark streuen und ein Fehler des Schwellwerts $<5$ vernachlässigbar ist. Es gibt Fälle in denen kein Hintergrund zu sehen ist, bzw. dieser aufgrund leichter Färbung nicht mehr klar abgrenzbar ist. In diesen Fällen ist das Maximum dunkler als normal. Empirisch wurde der Bereich $ > 200$ festgelegt, für das ein gültiger Hintergrund gefunden werden kann. Für den Fall dass das Maximum darunter liegt, wird für dieses Bild kein Hintergrund festgelegt. Dies hat Auswirkungen auf die Berechnung des Bsplines, da keine Merkmale für das Cluster vorhanden sind. Der Umgang mit diesem Fall wird in Abschnitt \ref{sec:bspline} festgelegt.  
Nach der Bestimmung der Bereiche "Hintergrund" und "Gefärbt" ergibt sich "Anderes" aus den bisher nicht festgelegten Pixeln. Vorausgesetzt wird jedoch, dass diese Pixel nach der Color Deconvolution im dritten Kanal nicht weiß sind, da dies Eigenschaften des gefärbten Bereichs bzw. eines sehr hellen Hintergrunds wären. Die Farbeeigenschaft von hellerem Plasma wird durch den Arcustangens oft nicht komplett erfasst. Um zu vermeiden dass diese Bereiche anschließend "Anderes" zugeordnet werden, wird die oben genannte Bedingung gestellt. 
 
\subsection{Bspline}\label{sec:bspline_own}

Die Implementierung der Bspline-Berechnung weißt viele Parallelen, aber auch Abweichungen gegenüber der von Khan\ref{sec:bspline} auf. Als Kontrollpunkte dienen die gleichen Merkmale der Histogramme, aber die Interpolation an den Sättigungsstellen ist unterschiedlich gesichert. Bei Khan gibt es mehrere zusätzliche Kontrollpunkte, in der vorliegenden Arbeit gibt es genau zwei, einen am unteren, den anderen am oberen Ende. Dass diese Punkte trotzdem interpoliert werden, liegt an der Anpassung des Knotenvektors, in dem den entsprechenden Knoten eine Vielfachheit $n$ zugewiesen wird, wobei $n$ auch dem Grad des Bsplines entspricht. Die verbleibenden Knoten werden gleichmäßig über das Parameterintervall verteilt. \citeauthor{khan2014nonlinear} schätzen den Knotenvektor indem sie ein lineares System mit Hilfe von Thikhonov Regularisierung lösen, wobei Intensitäten auf möglichst ähnliche Werte abgebildet werden sollen.  

\subsection{Auswahl Target}\label{sec:auswahl_target}

Erste Versuche zeigten, dass ein einzelnes Referenzbild nicht ausreicht, die Vielfältigkeit der Daten abzubilden. Aus diesem Grund wurde manuell ein Set aus 15 Bildern zusammengestellt, welches zum einen möglichst viele verschiedene Ausprägungen, sowie für die Segmentierung geeignete Bilder enthält. Für die Wahl der Referenz wurden unterschiedliche Konzepte entwickelt. Eine Möglichkeit besteht darin, eine Art mittleres Referenzbild zu berechnen, indem für jedes Merkmal, der Mittelwert aller korrespondierenden Merkmale der Referenzbilder gewählt wird. Eine Abwandlung hierzu ist es, den Median anstelle des Mittelwerts zu verwenden, wodurch Ausreißer kein Gewicht bekommen. In beiden Fällen bleiben die Referenzmerkmale für alle zu normalisierenden Bilder gleich. Eine andere Möglichkeit ist es für jedes Bild eine hinsichtlich der Merkmale möglichst ähnliche Referenz auszuwählen. Dadurch ist die Gefahr einer Verfälschung der Bildinformationen am wenigsten gegeben, der Grad der Anpassung über ein ganzes Set hinweg ist jedoch auch geringer.
  
\subsection{Evaluierung}\label{sec:evaluierung}

Die unterschiedlichen Ansätze zur Farbnormalisierung wurden in Hinblick auf die Qualität der Segmentierung und auf korrekte Klassifikation untersucht. Die dabei verwendeten Maße werden in den folgenden Abschnitten vorgestellt.


\subsubsection{Segmentierung}\label{sec:eval_segmentierung}

Für die Evaluation der Segmentierung, wurde der automatische Algorithmus mit den als Grundwahrheit dienenden manuell bestimmten Daten verglichen. Das verwendete Maß ist dabei eine Kombination aus Unter- bzw. Übersegmentierung und dem AOM-Kriterium, welches den Überlappungsbereich beschreibt. 

\noindent AOM-Kriterium:
\begin{equation}
Q_1 = \frac{|T\cap A|}{|T\cup A|}
\end{equation}
Übersegmentierung:
\begin{equation}
Q_2 = \frac{|T\setminus (A\cap T)|}{|T|}
\end{equation}
Untersegmentierung:
\begin{equation}
Q_3 = \frac{|A\setminus (A\cap T)|}{|A|}
\end{equation}

Soll Segmentierung der Zelle als ganzem betrachtet werden, so ist $A$ die Menge aller Punkte, welche laut automatischer Segmentierung zur Zelle gehören. $T$ steht für die äquivalente Menge entsprechend der Grundwahrheit.

\subsubsection{Klassifizierung}\label{sec:eval_klassifizierung}

